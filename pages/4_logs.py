# pages/4_logs.py - GeliÅŸmiÅŸ Log ve Monitoring Sistemi

import streamlit as st
import pandas as pd
import json
import sqlite3
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import sys
import time
import io
import csv

# Projenin ana dizinini Python'un arama yoluna ekle
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ğŸ¨ GLOBAL CSS YÃœKLEME
from utils.style_loader import load_global_css
load_global_css()


try:
    from operations.log_manager import LogManager, log_manager
    LOG_MANAGER_AVAILABLE = True
except ImportError:
    LOG_MANAGER_AVAILABLE = False

# Alternatif log source'larÄ±
def get_sync_history_logs():
    """Sync history JSON'dan log verilerini Ã§Ä±kar"""
    logs = []
    try:
        sync_file = os.path.join(project_root, 'sync_history.json')
        if os.path.exists(sync_file):
            with open(sync_file, 'r', encoding='utf-8') as f:
                sync_history = json.load(f)
            
            for i, sync in enumerate(sync_history):
                logs.append({
                    'id': i + 1,
                    'timestamp': sync.get('timestamp'),
                    'log_type': 'sync',
                    'status': 'completed' if sync.get('stats', {}).get('failed', 0) == 0 else 'partial',
                    'source': 'system',
                    'sync_mode': 'auto',
                    'processed': sync.get('stats', {}).get('processed', 0),
                    'created': sync.get('stats', {}).get('created', 0),
                    'updated': sync.get('stats', {}).get('updated', 0),
                    'failed': sync.get('stats', {}).get('failed', 0),
                    'skipped': sync.get('stats', {}).get('skipped', 0),
                    'details': json.dumps(sync.get('details', [])),
                    'duration': None,
                    'error_message': None
                })
    except Exception as e:
        st.error(f"Sync history yÃ¼klenirken hata: {e}")
    
    return logs

def get_system_logs():
    """Sistem loglarÄ±nÄ± Ã§ek"""
    logs = []
    try:
        log_dir = os.path.join(project_root, 'logs')
        if os.path.exists(log_dir):
            # SQLite veritabanÄ± varsa onu kontrol et
            db_path = os.path.join(log_dir, 'sync_logs.db')
            if os.path.exists(db_path):
                with sqlite3.connect(db_path) as conn:
                    cursor = conn.execute("""
                        SELECT id, timestamp, log_type, status, source, sync_mode,
                               processed, created, updated, failed, skipped, 
                               duration, error_message, details
                        FROM sync_logs 
                        ORDER BY timestamp DESC 
                        LIMIT 1000
                    """)
                    
                    columns = [desc[0] for desc in cursor.description]
                    for row in cursor.fetchall():
                        logs.append(dict(zip(columns, row)))
    except Exception as e:
        st.error(f"Sistem loglarÄ± yÃ¼klenirken hata: {e}")
    
    return logs

def load_css():
    try:
        with open(os.path.join(project_root, "style.css"), encoding='utf-8') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
    except FileNotFoundError:
        pass
    except UnicodeDecodeError:
        st.error("CSS dosyasÄ± encoding hatasÄ±.")

# GiriÅŸ kontrolÃ¼
if not st.session_state.get("authentication_status"):
    st.error("LÃ¼tfen bu sayfaya eriÅŸmek iÃ§in giriÅŸ yapÄ±n.")
    st.stop()

load_css()

# Page config
st.set_page_config(page_title="Logs & Monitoring", layout="wide")

st.markdown("""
<div class="main-header">
    <h1>ğŸ“Š GeliÅŸmiÅŸ Log ve Monitoring Sistemi</h1>
    <p>KapsamlÄ± sistem izleme, log analizi ve performans metrikleri</p>
</div>
""", unsafe_allow_html=True)

# Sidebar - GeliÅŸmiÅŸ Filtreler
with st.sidebar:
    st.header("ï¿½ GeliÅŸmiÅŸ Filtreler")
    
    # Veri kaynaÄŸÄ± seÃ§imi
    data_source = st.selectbox(
        "Veri KaynaÄŸÄ±",
        ["SQLite Database", "Sync History JSON", "Kombine GÃ¶rÃ¼nÃ¼m"],
        index=2
    )
    
    # Zaman aralÄ±ÄŸÄ±
    time_range = st.selectbox(
        "Zaman AralÄ±ÄŸÄ±",
        ["Son 1 Saat", "Son 6 Saat", "Son 24 Saat", "Son 7 GÃ¼n", "Son 30 GÃ¼n", "TÃ¼mÃ¼"],
        index=3
    )
    
    # Log seviyesi
    log_level = st.selectbox(
        "Log Seviyesi",
        ["TÃ¼mÃ¼", "Kritik Hatalar", "UyarÄ±lar", "Bilgi", "Debug"],
        index=0
    )
    
    # Ä°ÅŸlem tÃ¼rÃ¼
    operation_type = st.multiselect(
        "Ä°ÅŸlem TÃ¼rÃ¼",
        ["Senkronizasyon", "Fiyat GÃ¼ncelleme", "ÃœrÃ¼n OluÅŸturma", "ÃœrÃ¼n GÃ¼ncelleme", "Hata AyÄ±klama"],
        default=["Senkronizasyon"]
    )
    
    # BaÅŸarÄ± durumu
    success_filter = st.selectbox(
        "BaÅŸarÄ± Durumu",
        ["TÃ¼mÃ¼", "BaÅŸarÄ±lÄ±", "BaÅŸarÄ±sÄ±z", "KÄ±smi BaÅŸarÄ±", "Devam Eden"],
        index=0
    )
    
    # CanlÄ± izleme
    live_monitoring = st.checkbox("ğŸ”´ CanlÄ± Ä°zleme (5s)", value=False)
    
    # Ayarlar
    st.header("âš™ï¸ GÃ¶rÃ¼nÃ¼m AyarlarÄ±")
    show_charts = st.checkbox("ğŸ“Š Grafikleri GÃ¶ster", value=True)
    show_details = st.checkbox("ğŸ“‹ DetaylarÄ± GÃ¶ster", value=True)
    items_per_page = st.selectbox("Sayfa baÅŸÄ±na kayÄ±t", [25, 50, 100, 200], index=1)

# Ana iÃ§erik
# CanlÄ± yenileme
if live_monitoring:
    placeholder = st.empty()
    auto_refresh_placeholder = st.empty()
    
    with auto_refresh_placeholder:
        st.info("ğŸ”´ CanlÄ± izleme aktif - 5 saniyede bir yenileniyor...")

# Veri yÃ¼kleme
@st.cache_data(ttl=60)  # 1 dakika cache
def load_all_logs():
    all_logs = []
    
    if data_source in ["SQLite Database", "Kombine GÃ¶rÃ¼nÃ¼m"]:
        all_logs.extend(get_system_logs())
    
    if data_source in ["Sync History JSON", "Kombine GÃ¶rÃ¼nÃ¼m"]:
        all_logs.extend(get_sync_history_logs())
    
    return all_logs

# Veri yÃ¼kleme ve iÅŸleme
logs_data = load_all_logs()

if not logs_data:
    st.warning("ğŸ“­ HiÃ§ log verisi bulunamadÄ±. HenÃ¼z bir iÅŸlem yapÄ±lmamÄ±ÅŸ olabilir.")
    st.stop()

# DataFrame'e Ã§evir
df = pd.DataFrame(logs_data)
df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

# Filtreleme iÅŸlemleri
# Zaman filtresi
time_map = {
    "Son 1 Saat": 1/24,
    "Son 6 Saat": 6/24,
    "Son 24 Saat": 1,
    "Son 7 GÃ¼n": 7,
    "Son 30 GÃ¼n": 30,
    "TÃ¼mÃ¼": 365
}

if time_range != "TÃ¼mÃ¼":
    cutoff_time = datetime.now() - timedelta(days=time_map[time_range])
    df = df[df['timestamp'] >= cutoff_time]

# BaÅŸarÄ± durumu filtresi
if success_filter != "TÃ¼mÃ¼":
    status_map = {
        "BaÅŸarÄ±lÄ±": ["completed"],
        "BaÅŸarÄ±sÄ±z": ["failed"],
        "KÄ±smi BaÅŸarÄ±": ["partial"],
        "Devam Eden": ["running", "started"]
    }
    if success_filter in status_map:
        df = df[df['status'].isin(status_map[success_filter])]

# Ana Dashboard Metrikleri
if not df.empty:
    st.subheader("ğŸ“Š AnlÄ±k Sistem Durumu")
    
    # Ãœst metrikler
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        total_ops = len(df)
        st.metric("Toplam Ä°ÅŸlem", total_ops)
    
    with col2:
        successful_ops = len(df[df['status'] == 'completed'])
        success_rate = (successful_ops / total_ops * 100) if total_ops > 0 else 0
        st.metric("BaÅŸarÄ± OranÄ±", f"{success_rate:.1f}%", 
                 delta=f"{successful_ops}/{total_ops}")
    
    with col3:
        total_processed = df['processed'].sum()
        st.metric("Ä°ÅŸlenen ÃœrÃ¼n", f"{total_processed:,}")
    
    with col4:
        total_failed = df['failed'].sum()
        st.metric("BaÅŸarÄ±sÄ±z", total_failed, 
                 delta=-total_failed if total_failed > 0 else None,
                 delta_color="inverse")
    
    with col5:
        if not df.empty and df['timestamp'].notna().any():
            last_operation = df['timestamp'].max()
            time_since = datetime.now() - last_operation
            if time_since.total_seconds() < 3600:
                time_str = f"{int(time_since.total_seconds()/60)} dk Ã¶nce"
            elif time_since.total_seconds() < 86400:
                time_str = f"{int(time_since.total_seconds()/3600)} sa Ã¶nce"
            else:
                time_str = f"{time_since.days} gÃ¼n Ã¶nce"
            st.metric("Son Ä°ÅŸlem", time_str)

    # Sistem SaÄŸlÄ±k Durumu
    st.markdown("---")
    health_cols = st.columns([2, 1, 1])
    
    with health_cols[0]:
        if success_rate >= 95:
            st.success("âœ… Sistem MÃ¼kemmel Durumda")
        elif success_rate >= 85:
            st.warning("âš ï¸ Sistem Normal, BazÄ± UyarÄ±lar Var")
        else:
            st.error("âŒ Sistem Kritik Durumda")
    
    with health_cols[1]:
        recent_failures = len(df[(df['status'] == 'failed') & 
                               (df['timestamp'] >= datetime.now() - timedelta(hours=24))])
        st.metric("24s Ä°Ã§inde Hata", recent_failures)
    
    with health_cols[2]:
        avg_processing = df['processed'].mean() if not df.empty else 0
        st.metric("Ortalama Ä°ÅŸlem", f"{avg_processing:.0f}")

# GÃ¶rsel Analiz
if show_charts and not df.empty:
    st.markdown("---")
    st.subheader("ğŸ“ˆ GÃ¶rsel Analiz ve Trendler")
    
    # ÃœÃ§ ayrÄ± grafik sekmesi
    chart_tab1, chart_tab2, chart_tab3, chart_tab4 = st.tabs([
        "â±ï¸ Zaman Serisi", "ğŸ“Š Durum Analizi", "ğŸ”„ Ä°ÅŸlem PerformansÄ±", "ğŸ¯ DetaylÄ± Metrikler"
    ])
    
    with chart_tab1:
        # Zaman serisi analizi
        if len(df) > 1:
            # GÃ¼nlÃ¼k iÅŸlem sayÄ±sÄ±
            daily_stats = df.groupby([df['timestamp'].dt.date, 'status']).size().reset_index(name='count')
            daily_stats['timestamp'] = pd.to_datetime(daily_stats['timestamp'])
            
            fig = px.area(daily_stats, x='timestamp', y='count', color='status',
                         title="GÃ¼nlÃ¼k Ä°ÅŸlem DaÄŸÄ±lÄ±mÄ±",
                         labels={'count': 'Ä°ÅŸlem SayÄ±sÄ±', 'timestamp': 'Tarih'})
            st.plotly_chart(fig, use_container_width=True)
            
            # Saatlik aktivite haritasÄ±
            if len(df) > 24:
                df['hour'] = df['timestamp'].dt.hour
                df['day'] = df['timestamp'].dt.day_name()
                hourly_heatmap = df.groupby(['day', 'hour']).size().reset_index(name='count')
                
                if not hourly_heatmap.empty:
                    fig = px.density_heatmap(hourly_heatmap, x='hour', y='day', z='count',
                                           title="Saatlik Aktivite HaritasÄ±")
                    st.plotly_chart(fig, use_container_width=True)
    
    with chart_tab2:
        # Durum analizi
        col_chart1, col_chart2 = st.columns(2)
        
        with col_chart1:
            status_dist = df['status'].value_counts()
            fig = px.pie(values=status_dist.values, names=status_dist.index,
                        title="Ä°ÅŸlem Durumu DaÄŸÄ±lÄ±mÄ±")
            st.plotly_chart(fig, use_container_width=True)
        
        with col_chart2:
            source_dist = df['source'].value_counts()
            fig = px.bar(x=source_dist.values, y=source_dist.index, 
                        orientation='h', title="Kaynak DaÄŸÄ±lÄ±mÄ±")
            st.plotly_chart(fig, use_container_width=True)
    
    with chart_tab3:
        # Performance metrikleri
        if 'processed' in df.columns and df['processed'].sum() > 0:
            # Ä°ÅŸlem performance'Ä±
            perf_metrics = df.groupby(df['timestamp'].dt.date).agg({
                'processed': 'sum',
                'created': 'sum',
                'updated': 'sum',
                'failed': 'sum'
            }).reset_index()
            
            fig = make_subplots(rows=2, cols=2,
                              subplot_titles=('Ä°ÅŸlenen ÃœrÃ¼nler', 'OluÅŸturulan', 'GÃ¼ncellenen', 'BaÅŸarÄ±sÄ±z'))
            
            fig.add_trace(go.Scatter(x=perf_metrics['timestamp'], y=perf_metrics['processed'],
                                   name='Ä°ÅŸlenen'), row=1, col=1)
            fig.add_trace(go.Scatter(x=perf_metrics['timestamp'], y=perf_metrics['created'],
                                   name='OluÅŸturulan'), row=1, col=2)
            fig.add_trace(go.Scatter(x=perf_metrics['timestamp'], y=perf_metrics['updated'],
                                   name='GÃ¼ncellenen'), row=2, col=1)
            fig.add_trace(go.Scatter(x=perf_metrics['timestamp'], y=perf_metrics['failed'],
                                   name='BaÅŸarÄ±sÄ±z'), row=2, col=2)
            
            fig.update_layout(height=600, title_text="GÃ¼nlÃ¼k Performance Metrikleri")
            st.plotly_chart(fig, use_container_width=True)
    
    with chart_tab4:
        # DetaylÄ± metrikler
        if len(df) > 0:
            # Success rate trend
            df_sorted = df.sort_values('timestamp')
            df_sorted['success_rate_rolling'] = (
                df_sorted['status'].eq('completed').rolling(window=10, min_periods=1).mean() * 100
            )
            
            fig = px.line(df_sorted, x='timestamp', y='success_rate_rolling',
                         title="BaÅŸarÄ± OranÄ± Trendi (10 Ä°ÅŸlem OrtalamasÄ±)")
            fig.add_hline(y=95, line_dash="dash", line_color="green", 
                         annotation_text="Hedef: %95")
            st.plotly_chart(fig, use_container_width=True)

# DetaylÄ± Log Tablosu
if show_details:
    st.markdown("---")
    st.subheader("ğŸ“‹ DetaylÄ± Log KayÄ±tlarÄ±")
    
    # Arama ve filtreleme
    search_cols = st.columns([3, 1])
    with search_cols[0]:
        search_query = st.text_input("ğŸ” Log iÃ§eriÄŸinde ara:", 
                                   placeholder="ÃœrÃ¼n adÄ±, hata mesajÄ±, ID...")
    with search_cols[1]:
        sort_order = st.selectbox("SÄ±ralama", ["Yeni â†’ Eski", "Eski â†’ Yeni"])
    
    # Arama filtresi uygula
    display_df = df.copy()
    if search_query:
        mask = (
            display_df['details'].str.contains(search_query, case=False, na=False) |
            display_df['error_message'].str.contains(search_query, case=False, na=False)
        )
        display_df = display_df[mask]
    
    # SÄ±ralama
    if sort_order == "Eski â†’ Yeni":
        display_df = display_df.sort_values('timestamp')
    else:
        display_df = display_df.sort_values('timestamp', ascending=False)
    
    # Sayfalama
    total_records = len(display_df)
    total_pages = (total_records - 1) // items_per_page + 1 if total_records > 0 else 1
    
    page_cols = st.columns([1, 2, 1])
    with page_cols[1]:
        current_page = st.selectbox(
            f"Sayfa (Toplam: {total_pages}, KayÄ±t: {total_records})",
            range(1, total_pages + 1),
            index=0
        )
    
    # Sayfa verilerini al
    start_idx = (current_page - 1) * items_per_page
    end_idx = start_idx + items_per_page
    page_df = display_df.iloc[start_idx:end_idx]
    
    if not page_df.empty:
        # Tablo gÃ¶sterimi
        for idx, row in page_df.iterrows():
            with st.expander(
                f"ğŸ”¸ {row['timestamp'].strftime('%Y-%m-%d %H:%M:%S') if pd.notna(row['timestamp']) else 'N/A'} - "
                f"{row['log_type']} - {row['status']} "
                f"({row.get('processed', 0)} iÅŸlenen)",
                expanded=False
            ):
                detail_cols = st.columns([2, 2, 1])
                
                with detail_cols[0]:
                    st.write("**ğŸ“Š Ä°statistikler:**")
                    stats_html = f"""
                    - **Ä°ÅŸlenen:** {row.get('processed', 0)}
                    - **OluÅŸturulan:** {row.get('created', 0)}
                    - **GÃ¼ncellenen:** {row.get('updated', 0)}
                    - **BaÅŸarÄ±sÄ±z:** {row.get('failed', 0)}
                    - **Atlanan:** {row.get('skipped', 0)}
                    """
                    st.markdown(stats_html)
                
                with detail_cols[1]:
                    st.write("**â„¹ï¸ Detaylar:**")
                    info_html = f"""
                    - **ID:** {row.get('id', 'N/A')}
                    - **Kaynak:** {row.get('source', 'N/A')}
                    - **Mod:** {row.get('sync_mode', 'N/A')}
                    - **SÃ¼re:** {row.get('duration', 'N/A')}
                    """
                    st.markdown(info_html)
                
                with detail_cols[2]:
                    # Ä°ÅŸlem durumu gÃ¶stergesi
                    status = row.get('status', 'unknown')
                    if status == 'completed':
                        st.badge("BaÅŸarÄ±lÄ±", icon="âœ…", color="green")
                    elif status == 'failed':
                        st.badge("BaÅŸarÄ±sÄ±z", icon="âŒ", color="red")
                    elif status == 'partial':
                        st.badge("KÄ±smi", icon="âš ï¸", color="yellow")
                    else:
                        st.badge("DiÄŸer", icon="â„¹ï¸", color="gray")
                
                # Hata mesajÄ±
                if pd.notna(row.get('error_message')):
                    st.error(f"**Hata:** {row['error_message']}")
                
                # JSON detaylar
                if pd.notna(row.get('details')):
                    with st.expander("ğŸ“„ JSON DetaylarÄ±"):
                        try:
                            details_data = json.loads(row['details'])
                            st.json(details_data)
                        except:
                            st.text(row['details'])

# Export Ä°ÅŸlemleri
st.markdown("---")
st.subheader("ğŸ“¥ Export ve PaylaÅŸÄ±m")

export_cols = st.columns(4)

with export_cols[0]:
    if st.button("ğŸ“Š Excel Export", use_container_width=True):
        if not df.empty:
            # Excel dosyasÄ± oluÅŸtur
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                # Ana veriler
                export_df = df.copy()
                export_df['timestamp'] = export_df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
                export_df.to_excel(writer, sheet_name='Logs', index=False)
                
                # Ã–zet istatistikler
                summary_data = {
                    'Metrik': ['Toplam Ä°ÅŸlem', 'BaÅŸarÄ±lÄ±', 'BaÅŸarÄ±sÄ±z', 'BaÅŸarÄ± OranÄ±'],
                    'DeÄŸer': [len(df), successful_ops, len(df) - successful_ops, f"{success_rate:.1f}%"]
                }
                pd.DataFrame(summary_data).to_excel(writer, sheet_name='Ã–zet', index=False)
            
            st.download_button(
                label="ğŸ“ Excel DosyasÄ±nÄ± Ä°ndir",
                data=output.getvalue(),
                file_name=f"logs_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

with export_cols[1]:
    if st.button("ğŸ“„ CSV Export", use_container_width=True):
        if not df.empty:
            csv_buffer = io.StringIO()
            export_df = df.copy()
            export_df['timestamp'] = export_df['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
            export_df.to_csv(csv_buffer, index=False)
            
            st.download_button(
                label="ğŸ“ CSV DosyasÄ±nÄ± Ä°ndir",
                data=csv_buffer.getvalue(),
                file_name=f"logs_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

with export_cols[2]:
    if st.button("ğŸ§¹ Log Temizleme", use_container_width=True):
        st.warning("Bu Ã¶zellik geliÅŸtirilme aÅŸamasÄ±nda...")

with export_cols[3]:
    if st.button("âš ï¸ Alert Kurulumu", use_container_width=True):
        st.info("Alert sistemi geliÅŸtirilme aÅŸamasÄ±nda...")

# CanlÄ± yenileme
if live_monitoring:
    time.sleep(5)
    st.rerun()

